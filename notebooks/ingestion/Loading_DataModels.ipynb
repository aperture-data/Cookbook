{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Cookbook (DataModels).\n",
    "\n",
    "Following the concepts on the different [means](https://docs.aperturedata.io/HowToGuides/Ingestion/Ingestion#ingestion-based-on-the-data-model) of ingesting the data, we will build an example using the DataModel method in this notebook.\n",
    "\n",
    "We will use the [Cookbook dataset](https://docs.google.com/spreadsheets/d/1G1HPG3Dxx5W39OD6b74wMHvWupD7N-DLUbV7tD5owx8/edit?usp=sharing) to have the data persisted onto ApertureDB instance.\n",
    "\n",
    "> #### Note\n",
    "> The notebook assumes that the SDK has been setup as per the instructions.\n",
    ">\n",
    "> Colab one time setup [instructions](/Setup/client/notebooks?notebooks=colab).\n",
    ">\n",
    "> Non ephemeral jupyter server one time setup [instructions](/Setup/client/notebooks?notebooks=notebook).\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed resources.\n",
    "- ```create_nested_json.py```: The script merges the first 3 sheets on the source into a json file such that there will be a list of Dishes objects, and each Dish may have multiple ingredients, and each ingredient has miscellaneous properties. This ends up as a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-01 16:33:55--  https://github.com/aperture-data/Cookbook/raw/refs/heads/main/scripts/create_nested_json.py\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/aperture-data/Cookbook/refs/heads/main/scripts/create_nested_json.py [following]\n",
      "--2024-10-01 16:33:55--  https://raw.githubusercontent.com/aperture-data/Cookbook/refs/heads/main/scripts/create_nested_json.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1757 (1.7K) [text/plain]\n",
      "Saving to: ‘create_nested_json.py’\n",
      "\n",
      "create_nested_json. 100%[===================>]   1.72K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-01 16:33:56 (18.6 MB/s) - ‘create_nested_json.py’ saved [1757/1757]\n",
      "\n",
      "/Users/gsaluja/Projects/ad/Cookbook/notebooks/ingestion/create_nested_json.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  \"name\"]).apply(dish_ingredients_aggregator).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Get the script to generate the data.json\n",
    "!wget https://github.com/aperture-data/Cookbook/raw/refs/heads/main/scripts/create_nested_json.py\n",
    "\n",
    "# Run the script to generate the data.json\n",
    "!python create_nested_json.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data model definitions.\n",
    "\n",
    "A popular way to define the schema in python is using pydantic, and we shall use the same to create the associations of our Cookbook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from aperturedb.DataModels import  ImageDataModel, IdentityDataModel\n",
    "\n",
    "class Ingredient(IdentityDataModel):\n",
    "    Name: str\n",
    "    other_names: Optional[str] = \"\"\n",
    "    macronutrient: Optional[str] = \"\"\n",
    "    micronutrient: Optional[str] = \"\"\n",
    "    subgroup: Optional[str] = \"\"\n",
    "    category: Optional[str] = \"\"\n",
    "\n",
    "class Dish(ImageDataModel):\n",
    "    contributor: str\n",
    "    name: str\n",
    "    location: str\n",
    "    caption: str\n",
    "    recipe_url: str\n",
    "    cuisine: str\n",
    "    dish_id: int\n",
    "    ingredients: List[Ingredient]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create objects of these models.\n",
    "\n",
    "The Objects get provisioned using the json file generated by running the script ```create_nested_json.py```\n",
    "\n",
    "Example line from the json file:\n",
    "\n",
    "> Sample record in dishes.json\n",
    ">```json\n",
    ">{\n",
    ">    \"dish_id\": 1,\n",
    ">    \"url\": \"https://raw.githubusercontent.com/aperture-data/Cookbook/refs/heads/main/images/001 Large.jpeg\",\n",
    ">    \"type\": \"main dish\",\n",
    ">    \"location\": \"NJ\",\n",
    ">    \"cuisine\": \"Indian\",\n",
    ">    \"recipe_url\": \"https://www.tarladalal.com/rajma-chawal-punjabi-rajma-chawal-4951r\",\n",
    ">    \"contributor\": \"gautam\",\n",
    ">    \"caption\": \"Beans with rice\",\n",
    ">    \"name\": \"rajma chawal\",\n",
    ">    \"ingredients\": [\n",
    ">      {\n",
    ">        \"Name\": \"red kidney beans\",\n",
    ">        \"other_names\": \"rajma\",\n",
    ">        \"category\": \"vegetarian\",\n",
    ">        \"subgroup\": \"legume\",\n",
    ">        \"macronutrient\": \"protein\"\n",
    ">      },\n",
    ">      {\n",
    ">        \"Name\": \"rice\",\n",
    ">        \"other_names\": \"chawal\",\n",
    ">        \"category\": \"vegetarian\",\n",
    ">        \"subgroup\": \"grain\",\n",
    ">        \"macronutrient\": \"carbohydrates\"\n",
    ">      }\n",
    ">    ]\n",
    ">  }\n",
    ">```\n",
    "\n",
    "\n",
    "These objects can be passed to a function called ```generate_add_query``` which takes care of generating the queries that ApertureDB can execute to persist the objects on the DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and execute queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fd6b72aa6c43cebbb4cfdd8e8b88d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aperturedb.Query import generate_add_query\n",
    "from aperturedb.CommonLibrary import  execute_query, create_connector\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "with open(\"dishes.json\") as ins:\n",
    "    client = create_connector()\n",
    "    dishes = json.load(ins)\n",
    "    for dish in tqdm(dishes):\n",
    "        #Create the Dish object, along with it's ingredients\n",
    "        dish = Dish(**dish)\n",
    "\n",
    "        # Create a query to be run against the database\n",
    "        query, blobs, _ = generate_add_query(dish)\n",
    "\n",
    "        # Execute the query. The client has been setup.\n",
    "        result, response, output_blobs = execute_query(client, query, blobs)\n",
    "        if result != 0:\n",
    "            print(response)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
